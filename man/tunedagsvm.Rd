% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tunedagsvm.R
\name{tunedagsvm}
\alias{tunedagsvm}
\title{Tunes a Directed Acyclic Graph-Support Vector Machine.}
\source{
The function relies on the R packages \code{raster}
(\insertCite{Hijmans.2017}{TraceIdentification}), \code{e1071}
(\insertCite{Meyer.2015}{TraceIdentification}), \code{caret}
(\insertCite{Kuhn.2018}{TraceIdentification}), \code{Hmisc}
(\insertCite{HarrellJr.2018}{TraceIdentification}), \code{doParallel}
(\insertCite{Weston.2017}{TraceIdentification}) and \code{foreach}
(\insertCite{Weston.2017b}{TraceIdentification}).
}
\usage{
tunedagsvm(testandtrainingsample, crossvalidationfolds = 10)
}
\arguments{
\item{testandtrainingsample}{The provided test and training sample
(\code{data.frame} objetc) as returned by \code{\link{gettestandtrainingsampledf}}.}

\item{crossvalidationfolds}{A numeric value representing the number of folds (random subsets)
to use during cross-validation.}
}
\value{
The function returns a list with two elements:
\describe{
  \item{\code{optimparam}}{A \code{data.frame} object containing for each node and
  kernel the tuned parameter values and various performance measures as returned by
  \code{\link[caret]{confusionMatrix}}.}
  \item{\code{svm_fit_list}}{A list with an element for each kernel and node of the
  constructed DAG-SVM. Each element represents the tuned SVM for each kernel and node.
  The elements are named as kernel_layer_node where kernel is the respective kernel,
  layer the index of the layer and node the index of the node in the layer.}
}
}
\description{
\code{tunedagsvm} constructs based on a provided test and training sample as
returned by \code{\link{gettestandtrainingsampledf}} a directed acyclic graph-
support vector machine (DAG-SVM) \insertCite{Platt.2000}{TraceIdentification}
in order to discriminate the classes in the
provided test and training sample. This is done by implementing a simple grid
search as suggested by \insertCite{Chang.2001}{TraceIdentification}. The DAG-SVM is tuned for the follwing parameters:
\describe{
  \item{kernels:}{linear, sigmoidal, radial.}
  \item{\eqn{gamma}:}{\eqn{2^{-20}, 2^{-18}, …, 2^6} (not for the linear kernel)}
  \item{\eqn{C} (cost):}{
  \enumerate{
    \item In a first rough search step: \eqn{2^{-10}, 2^{-8}, …, 2^{10}}.
    \item In a following finer search step: \eqn{\text{C}_{\text{initial}} - 1.2, \text{C}_{\text{initial}} - 1.0,…, \text{C}_{\text{initial}}, \text{C}_{\text{initial}} + 1.0, \text{C}_{\text{initial}} + 1.2}
  }}
}
Tuning is done via random subset cross-validation. Tuning is done in parallel for each kernel.
Each node of the DAG-SVM is trained separately and the function provides performance
measures for the classification and a tuned model for each node and kernel.
}
\examples{
#
}
\references{
\insertAllCited{}
}
\seealso{
\code{\link{gettestandtrainingsampledf}}.
}
